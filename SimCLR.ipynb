{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SimCLR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('3.7.6': pyenv)",
      "language": "python",
      "name": "python37664bit376pyenv9dc5dbfe0601400392632ddcd12f4be3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JEwbldGLI3jE"
      },
      "source": [
        "This notebook contains a PyTorch implementation of the paper [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) by Chen et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL4EYthQfwcO",
        "colab_type": "text"
      },
      "source": [
        "**Try to modify the CLR to train a 100x100 pic data-set.**\n",
        "One way is to generate a CIFAR-10 compiliable data-sets, but this way needs to customize CIFAR-10 class.\n",
        "Another way, instead of using CIFAR-10, directly load data. I will try the latter way.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSpSFIt5zuuk",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as tfs\n",
        "from torchvision.datasets import *\n",
        "from torchvision.models import *\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZ0gavHPzuuq",
        "colab": {}
      },
      "source": [
        "tf_tr = tfs.Compose([\n",
        "    tfs.RandomResizedCrop(32),\n",
        "    tfs.RandomHorizontalFlip(),\n",
        "    tfs.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_de = tfs.Compose([\n",
        "    tfs.Resize(32),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_te = tfs.Compose([\n",
        "    tfs.Resize(32),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYPE0H5ezuut",
        "colab": {}
      },
      "source": [
        "class CustomCIFAR10(CIFAR10):\n",
        "    def __init__(self, **kwds):\n",
        "        super().__init__(**kwds)\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        if not self.train:\n",
        "            return super().__getitem__(idx)\n",
        "    \n",
        "        img = self.data[idx]\n",
        "        img = Image.fromarray(img).convert('RGB')\n",
        "        imgs = [self.transform(img), self.transform(img)]\n",
        "        return torch.stack(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNz2xfULRtuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomCervicalCIFAR10(CIFAR10):\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(CIFAR10, self).__init__(root, transform=transform,\n",
        "                                      target_transform=target_transform)\n",
        "        \n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        if self.train:\n",
        "            downloaded_list = self.train_list\n",
        "        else:\n",
        "            downloaded_list = self.test_list\n",
        "\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        for file_name, checksum in downloaded_list:\n",
        "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    entry = pickle.load(f)\n",
        "                else:\n",
        "                    entry = pickle.load(f, encoding='latin1')\n",
        "                self.data.append(entry['data'])\n",
        "                if 'labels' in entry:\n",
        "                    self.targets.extend(entry['labels'])\n",
        "                else:\n",
        "                    self.targets.extend(entry['fine_labels'])\n",
        "\n",
        "        self.data = np.vstack(self.data).reshape(-1,3,32,32)\n",
        "        self.data = self.data.tranpose((0,2,3,1))  #covert to HWC\n",
        "\n",
        "        self._load_meta()\n",
        "    \n",
        "    def _load_meta(self):\n",
        "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
        "        if not check_integrity(path, self.meta['md5']):\n",
        "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
        "                               ' You can use download=True to download it')\n",
        "        with open(path, 'rb') as infile:\n",
        "            if sys.version_info[0] == 2:\n",
        "                data = pickle.load(infile)\n",
        "            else:\n",
        "                data = pickle.load(infile, encoding='latin1')\n",
        "            self.classes = data[self.meta['key']]\n",
        "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3diHt5Cszuuz",
        "colab": {}
      },
      "source": [
        "ds_tr = CustomCIFAR10(root='data', train=True, transform=tf_tr, download=True)\n",
        "ds_de = CIFAR10(root='data', train=True, transform=tf_de, download=True)\n",
        "ds_te = CIFAR10(root='data', train=False, transform=tf_te, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WJ3Gu4Azuu6",
        "colab": {}
      },
      "source": [
        "dl_tr = DataLoader(ds_tr, batch_size=256, shuffle=True)\n",
        "dl_de = DataLoader(ds_de, batch_size=256, shuffle=True)\n",
        "dl_te = DataLoader(ds_te, batch_size=256, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VR72XmwUzuu9",
        "colab": {}
      },
      "source": [
        "model = resnet50(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "model.maxpool = nn.Identity()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qGByvqC00OST",
        "colab": {}
      },
      "source": [
        "ch = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Linear(ch, ch),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(ch, ch))\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXT6GGhEzuvA",
        "colab": {}
      },
      "source": [
        "def pair_cosine_similarity(x, eps=1e-8):\n",
        "    n = x.norm(p=2, dim=1, keepdim=True)\n",
        "    return (x @ x.t()) / (n * n.t()).clamp(min=eps)\n",
        "\n",
        "def nt_xent(x, t=0.5):\n",
        "    x = pair_cosine_similarity(x)\n",
        "    x = torch.exp(x / t)\n",
        "    idx = torch.arange(x.size()[0])\n",
        "    # Put positive pairs on the diagonal\n",
        "    idx[::2] += 1\n",
        "    idx[1::2] -= 1\n",
        "    x = x[idx]\n",
        "    # subtract the similarity of 1 from the numerator\n",
        "    x = x.diag() / (x.sum(0) - torch.exp(torch.tensor(1 / t)))\n",
        "    return -torch.log(x.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "av1krLFbzuvD",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1cGKFbmtzuvG",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "for i in range(100):\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_tr)\n",
        "    for data in pBar:\n",
        "        d = data.size()\n",
        "        x = data.view(d[0]*2, d[2], d[3], d[4]).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = nt_xent(p)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (i+1) % 10 == 0:\n",
        "        torch.save(model.state_dict(), path+'cifar10-rn50-mlp-b256-t0.5-e'+str(i+1)+'.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XIUNcQ8hzuvJ",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5D3vwJfCzuvM",
        "colab": {}
      },
      "source": [
        "model.fc = nn.Linear(ch, len(ds_de.classes))\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yU_vtz07zuvO",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.003)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2cEyaelzuvR",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "for i in range(5):\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_de)\n",
        "    for data in pBar:\n",
        "        x, y = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = criterion(p, y)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dHvJFQtu9V6Z",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6kOT_AtB9V9S",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "for i in range(5):\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_de)\n",
        "    for data in pBar:\n",
        "        x, y = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = criterion(p, y)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mWaBDzuzuvV",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "c, s = 0, 0\n",
        "pBar = tqdm(dl_te)\n",
        "for data in pBar:\n",
        "    x, y, = data[0].to(device), data[1].to(device)\n",
        "    p = model(x)\n",
        "    loss = criterion(p, y)\n",
        "    s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "    c += len(p)\n",
        "    pBar.set_description('Test: '+str(round(float(s),3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ayuXE4AwzuvY",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "y_pred, y_true = [], []\n",
        "pBar = tqdm(dl_te)\n",
        "for data in pBar:\n",
        "    x, y = data[0].to(device), data[1].to(device)\n",
        "    p = model(x)\n",
        "    y_pred.append(p.cpu().detach().numpy())\n",
        "    y_true.append(y.cpu().detach().numpy())\n",
        "y_pred = np.concatenate(y_pred)\n",
        "y_true = np.concatenate(y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rne3BUImzuvb",
        "colab": {}
      },
      "source": [
        "(y_true == y_pred.argmax(axis=1)).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b6E-ItwDd9dw",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}